{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Neuropixels Extracellular Electrophysiology </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">August 2019</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/EphysObservatory/neuropixels.png\" height=\"250\" width=\"250\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "import allensdk.brain_observatory.ecephys.ecephys_session as ecephys_session\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = os.path.join('/local1/storage/allensdk_cache/ecephys_project_cache', 'manifest.json')\n",
    "\n",
    "# manifest_path = os.path.join(\n",
    "#     \"/\",\n",
    "#     \"allen\",\n",
    "#     \"aibs\",\n",
    "#     \"informatics\",\n",
    "#     \"nileg\",\n",
    "#     \"swdb_ecephys\",\n",
    "#     \"cache_dir\",\n",
    "#     \"manifest.json\"\n",
    "# )\n",
    "\n",
    "lims_config = {\n",
    "    \"pg_kwargs\": {\n",
    "        \"dbname\": \"lims2_nileg\",\n",
    "        \"host\": \"aibsdc-dev-db1\",\n",
    "        \"port\": 5432,\n",
    "        \"user\": \"limsreader\",\n",
    "        \"password\": \"limsro\"\n",
    "    },\n",
    "    \"app_kwargs\": {\n",
    "        \"host\": \"10.128.50.64:3000\"\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "cache = EcephysProjectCache.from_lims(manifest=manifest_path, lims_kwargs=lims_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring an experimental session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = cache.get_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>genotype</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>project_code</th>\n",
       "      <th>probe_count</th>\n",
       "      <th>channel_count</th>\n",
       "      <th>unit_count</th>\n",
       "      <th>has_nwb</th>\n",
       "      <th>structure_acronyms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715093703</th>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>699733581</td>\n",
       "      <td>Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>M</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NeuropixelVisualCoding</td>\n",
       "      <td>6</td>\n",
       "      <td>765</td>\n",
       "      <td>1390</td>\n",
       "      <td>False</td>\n",
       "      <td>[CA, DG, MB, TH, VIS, VISam, VISl, VISp, VISpm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719161530</th>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>703279284</td>\n",
       "      <td>Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>M</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NeuropixelVisualCoding</td>\n",
       "      <td>6</td>\n",
       "      <td>616</td>\n",
       "      <td>1184</td>\n",
       "      <td>False</td>\n",
       "      <td>[CA, DG, MB, TH, VISal, VISam, VISl, VISp, VIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721123822</th>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>707296982</td>\n",
       "      <td>Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>M</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NeuropixelVisualCoding</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>265</td>\n",
       "      <td>True</td>\n",
       "      <td>[CA, DG, MB, TH, VIS, VISal, VISam, VISl, VISp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728680079</th>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>714089558</td>\n",
       "      <td>Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>M</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NeuropixelVisualCoding</td>\n",
       "      <td>6</td>\n",
       "      <td>636</td>\n",
       "      <td>1126</td>\n",
       "      <td>False</td>\n",
       "      <td>[CA, DG, MB, TH, VIS, VISp, VISpm, VISrl, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729090175</th>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>715075382</td>\n",
       "      <td>Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>F</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NeuropixelVisualCoding</td>\n",
       "      <td>6</td>\n",
       "      <td>594</td>\n",
       "      <td>1157</td>\n",
       "      <td>False</td>\n",
       "      <td>[CA, DG, TH, VISal, VISam, VISl, VISp, VISpm, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    session_type  specimen_id  \\\n",
       "id                                              \n",
       "715093703  brain_observatory_1.1    699733581   \n",
       "719161530  brain_observatory_1.1    703279284   \n",
       "721123822  brain_observatory_1.1    707296982   \n",
       "728680079  brain_observatory_1.1    714089558   \n",
       "729090175  brain_observatory_1.1    715075382   \n",
       "\n",
       "                                                  genotype gender  \\\n",
       "id                                                                  \n",
       "715093703    Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt      M   \n",
       "719161530    Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt      M   \n",
       "721123822  Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt      M   \n",
       "728680079    Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt      M   \n",
       "729090175  Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt      F   \n",
       "\n",
       "           age_in_days            project_code  probe_count  channel_count  \\\n",
       "id                                                                           \n",
       "715093703        118.0  NeuropixelVisualCoding            6            765   \n",
       "719161530        122.0  NeuropixelVisualCoding            6            616   \n",
       "721123822        125.0  NeuropixelVisualCoding            2            180   \n",
       "728680079        109.0  NeuropixelVisualCoding            6            636   \n",
       "729090175        118.0  NeuropixelVisualCoding            6            594   \n",
       "\n",
       "           unit_count  has_nwb  \\\n",
       "id                               \n",
       "715093703        1390    False   \n",
       "719161530        1184    False   \n",
       "721123822         265     True   \n",
       "728680079        1126    False   \n",
       "729090175        1157    False   \n",
       "\n",
       "                                          structure_acronyms  \n",
       "id                                                            \n",
       "715093703  [CA, DG, MB, TH, VIS, VISam, VISl, VISp, VISpm...  \n",
       "719161530  [CA, DG, MB, TH, VISal, VISam, VISl, VISp, VIS...  \n",
       "721123822  [CA, DG, MB, TH, VIS, VISal, VISam, VISl, VISp...  \n",
       "728680079    [CA, DG, MB, TH, VIS, VISp, VISpm, VISrl, None]  \n",
       "729090175  [CA, DG, TH, VISal, VISam, VISl, VISp, VISpm, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here's where I'd like to explore some dimensions of the dataset in terms of stimuli, cre lines, other metadata.  Ultimately I want to use this to select a particular session, rather than pull one arbitrarily***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:downloading a potentially large file from http://10.128.50.64:3000/well_known_files/download/851889779?wkf_id=851889779\n"
     ]
    }
   ],
   "source": [
    "session_id = 797828357 # for example\n",
    "session = cache.get_session_data(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_type                                      brain_observatory_1.1\n",
       "specimen_id                                                   776061251\n",
       "genotype                Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt\n",
       "gender                                                                M\n",
       "age_in_days                                                           0\n",
       "project_code                                     NeuropixelVisualCoding\n",
       "probe_count                                                           6\n",
       "channel_count                                                       604\n",
       "unit_count                                                         1076\n",
       "has_nwb                                                            True\n",
       "structure_acronyms    [CA, DG, MB, TH, VISal, VISam, VISl, VISp, VIS...\n",
       "Name: 797828357, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions.loc[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data for a session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by exploring tab completion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ElectrodeGroup' object has no attribute 'sampling_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c7e67b3079c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property_mixin.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLazyPropertyMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLazyPropertyMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/brain_observatory/ecephys/ecephys_session.py\u001b[0m in \u001b[0;36m_build_units_table\u001b[0;34m(self, units_table)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_units_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mprobes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unmerged_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property_mixin.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLazyPropertyMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLazyPropertyMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/core/lazy_property/lazy_property.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/AllenSDK/allensdk/brain_observatory/ecephys/ecephys_session_api/ecephys_nwb_session_api.py\u001b[0m in \u001b[0;36mget_probes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;34m'description'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;34m'location'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0;34m\"sampling_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;34m\"lfp_sampling_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfp_sampling_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ElectrodeGroup' object has no attribute 'sampling_rate'"
     ]
    }
   ],
   "source": [
    "session.units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.units.sampling_rate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is firing_rate? mean firing rate across the entire session? baseline firing rate during some window?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many units are in this session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(session.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which areas (structures) are they from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.units.structure_acronym.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***Nile add link to brainmap.org for a specific structure acronym***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many units per area are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.units.structure_acronym.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = session.spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(session.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_times.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the unit_id for the first unit to get the spike times for that unit. How many spikes does it have in the entire session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times[session.units.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spike_times[session.units.index[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a raster plot for the first 100 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(100):\n",
    "    plt.plot(spike_times[session.units.index[i]], np.repeat(i,len(spike_times[session.units.index[i]])), '|')#, color='gray')\n",
    "# plt.xlim(2000,2250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulus presentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else can we learn about the session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stimulus_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_pres = session.stimulus_presentations\n",
    "stim_pres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***need to fix the stimulus names?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explain epochs vs presentations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where is the stimulus epochs? replace function below when function exists in sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimulus_epochs():\n",
    "    stim_presentations = session.stimulus_presentations\n",
    "    stim_presentations.loc[stim_presentations.stimulus_block.isna(), 'stimulus_block'] = stim_presentations.stimulus_block.max()+1\n",
    "    stimulus_epochs = pd.DataFrame(columns=('stimulus','start','end'))\n",
    "    for i,a in enumerate(stim_presentations.stimulus_block.unique()):\n",
    "        temp = stim_presentations[stim_presentations.stimulus_block==a]\n",
    "        if temp.stimulus_name.iloc[0] == 'spontaneous_activity':\n",
    "            for index,row in temp.iterrows():\n",
    "                if row.duration>90:\n",
    "                    stimulus_epochs = stimulus_epochs.append(pd.DataFrame([[row.stimulus_name, row.start_time, row.stop_time]],columns=('stimulus','start','end')), ignore_index=True)\n",
    "        else:\n",
    "            stimulus_name = temp.stimulus_name.iloc[0]\n",
    "            start_time = temp.start_time.iloc[0]\n",
    "            stop_time = temp.stop_time.iloc[-1]\n",
    "            stimulus_epochs = stimulus_epochs.append(pd.DataFrame([[stimulus_name, start_time, stop_time]],\n",
    "                                                                  columns=('stimulus','start','end')),ignore_index=True)\n",
    "    stimulus_epochs.sort_values(by=['start'], inplace=True)\n",
    "    return stimulus_epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_epochs = get_stimulus_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_epochs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stimulus_epochs.stimulus.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shade each stimulus with a unique color. The plt.axvspan() is a useful function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(100):\n",
    "    plt.plot(spike_times[session.units.index[i]], np.repeat(i,len(spike_times[session.units.index[i]])), '|', alpha=0.5)#, color='gray')\n",
    "\n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c,stim_name in enumerate(stimulus_epochs.stimulus.unique()):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(xmin=stim.start.iloc[j], xmax=stim.end.iloc[j], color=colors[c], alpha=0.1)\n",
    "# plt.xlim(6000,7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the running speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(session.running_speed.end_time, session.running_speed.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the running speed to the visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(100):\n",
    "    plt.plot(spike_times[session.units.index[i]], np.repeat(i,len(spike_times[session.units.index[i]])), '|', alpha=0.5)#, color='gray')\n",
    "plt.plot(session.running_speed.end_time, (0.4*session.running_speed.velocity)-20)\n",
    "    \n",
    "    \n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c,stim_name in enumerate(stimulus_epochs.stimulus.unique()):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(xmin=stim.start.iloc[j], xmax=stim.end.iloc[j], color=colors[c], alpha=0.1)\n",
    "        \n",
    "\n",
    "\n",
    "plt.xlim(6000,8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "i=0\n",
    "plt.plot(spike_times[session.units.index[i]], np.repeat(i,len(spike_times[session.units.index[i]])), '|', alpha=0.5)#, color='gray')\n",
    "plt.plot(session.running_speed.end_time, (0.4*session.running_speed.velocity)-20)\n",
    "    \n",
    "    \n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c,stim_name in enumerate(stimulus_epochs.stimulus.unique()):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(xmin=stim.start.iloc[j], xmax=stim.end.iloc[j], color=colors[c], alpha=0.1)\n",
    "        \n",
    "\n",
    "\n",
    "plt.xlim(6000,8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "i=40\n",
    "plt.plot(spike_times[session.units.index[i]], np.repeat(0,len(spike_times[session.units.index[i]])), '|', alpha=0.5)#, color='gray')\n",
    "plt.plot(session.running_speed.end_time, (0.4*session.running_speed.velocity)-20)\n",
    "    \n",
    "    \n",
    "colors = ['blue','orange','green','red','yellow','purple','magenta','gray','lightblue']\n",
    "for c,stim_name in enumerate(stimulus_epochs.stimulus.unique()):\n",
    "    stim = stimulus_epochs[stimulus_epochs.stimulus==stim_name]\n",
    "    for j in range(len(stim)):\n",
    "        plt.axvspan(xmin=stim.start.iloc[j], xmax=stim.end.iloc[j], color=colors[c], alpha=0.1)\n",
    "        \n",
    "\n",
    "\n",
    "plt.xlim(6000,8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(spike_times[session.units.index[40]], np.repeat(5,len(spike_times[session.units.index[40]])), '|', alpha=0.5)#, color='gray')\n",
    "plt.plot(spike_times[session.units.index[0]], np.repeat(0,len(spike_times[session.units.index[0]])), '|', alpha=0.5)#, color='gray')\n",
    "plt.plot(session.running_speed.end_time, (0.4*session.running_speed.velocity)-20)\n",
    "plt.xlim(6000,8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and sorting units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a function to plot the raster plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** replace with call to api?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allensdk.brain_observatory.ecephys.visualization as ecvis\n",
    "# ecvis.raster_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(spike_times, start, end):\n",
    "    num_units = len(spike_times)\n",
    "    ystep = 1 / num_units\n",
    "\n",
    "    ymin = 0\n",
    "    ymax = ystep\n",
    "\n",
    "    for unit_id, unit_spike_times in spike_times.items():\n",
    "        unit_spike_times = unit_spike_times[np.logical_and(unit_spike_times >= start, unit_spike_times < end)]\n",
    "        plt.vlines(unit_spike_times, ymin=ymin, ymax=ymax)\n",
    "\n",
    "        ymin += ystep\n",
    "        ymax += ystep\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single stimulus presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drifting_gratings_presentation_onsets = session.stimulus_presentations.loc[\n",
    "    session.stimulus_presentations[\"stimulus_name\"] == \"drifting_gratings\", \n",
    "    \"start_time\"\n",
    "].values\n",
    "start, end = drifting_gratings_presentation_onsets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raster(session.spike_times, start, end)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Units')\n",
    "plt.tick_params(axis=\"y\", labelleft=False, left=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arrange neurons by their firing rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Comments: 1) remove hide the quality column; 2) remove sampling rate column - it is the same!  3) remove valid_data ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session.units.sort_values(by=\"firing_rate\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_fr = session.units.sort_values(by=\"firing_rate\", ascending=False)\n",
    "spike_times_by_firing_rate = {\n",
    "    uid: session.spike_times[uid] for uid in by_fr.index.values\n",
    "}\n",
    "\n",
    "plot_raster(spike_times_by_firing_rate, start, end)\n",
    "plt.ylabel('Units')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show the qc metrics of differnet units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### narrow down the session parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_params = session.units.loc[:, [\"structure_acronym\", \"probe_id\",\"firing_rate\", \"isi_violations\", \"snr\",'probe_vertical_position']]\n",
    "session_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort the current session parameters by ISI violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_params.sort_values(by=\"isi_violations\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe what is the isi violation? write the down the equation for that!\n",
    "Metrics\n",
    "\n",
    "1) ISI violation: equation, then plot spike train with the clear spike violation!\n",
    "2) from Josh: get the ISI, FR etc as metrics where the data is good! what are the thresholds for the good data? SNR + ISI violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the ISI violation distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(1 + session_params[\"isi_violations\"].values), bins=100)\n",
    "plt.xlabel('log10(1 + isi_violations)')\n",
    "plt.ylabel('unit count')\n",
    "plt.title('distribution of the isi violations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_units = session_params[\n",
    "    (session_params[\"isi_violations\"] < 0.2)\n",
    "    & (session_params[\"snr\"] > 2)\n",
    "]\n",
    "\n",
    "print('Number of units with reasonable ISI and SNR:')\n",
    "print(good_units.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locations of units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### describe the area with reasonable qc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_units.structure_acronym.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### plot the firing rate of the units with regards to structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb = session.units.groupby(\"structure_acronym\")\n",
    "\n",
    "structures = []\n",
    "data = []\n",
    "\n",
    "for group in gb:\n",
    "    structure, current_data = group\n",
    "    structures.append(structure)\n",
    "    data.append(current_data[\"firing_rate\"].values)\n",
    "\n",
    "axs = plt.gca()\n",
    "    \n",
    "plt.violinplot(data)\n",
    "\n",
    "axs.set_xticks(np.arange(len(structures))+1)\n",
    "axs.set_xticklabels(structures)\n",
    "plt.ylabel('Firing-rate (Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations on probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots()\n",
    "plt.hist(session_params[\"probe_vertical_position\"].values, bins=100)\n",
    "plt.xlabel('probe_vertical_position (mm)')\n",
    "plt.ylabel('unit count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit waveforms\n",
    "\n",
    "We store precomputed mean waveforms for each unit in the `mean_waveforms` attribute on the `EcephysSession` object. This is a dictionary which maps unit ids to xarray dataarrays. These have channel and time (seconds, aligned to the detected event times) dimensions. The data values are millivolts, as measured at the recording site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = session.mean_waveforms\n",
    "type(waveforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all waveforms for one unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = session.units.index.values[400]\n",
    "wf = session.mean_waveforms[unit]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.pcolormesh(wf, X=wf.time)\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Channel #')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out where each channel is located in the brain using the function `ecephys_session.intervals_structures`, which will identify channels that serve as reference points for the boundaries between identified brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in the list of channels from the CSD\n",
    "channels = session.channels.loc[csd.channel]\n",
    "structure_acronyms, intervals = ecephys_session.intervals_structures(channels)\n",
    "interval_midpoints = [ (aa + bb) / 2 for aa, bb in zip(intervals[:-1], intervals[1:])]\n",
    "print(structure_acronyms)\n",
    "print(interval_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(wf, X=wf.time)\n",
    "plt.colorbar(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_yticks(intervals)\n",
    "ax.set_yticks(interval_midpoints, minor=True)\n",
    "ax.set_yticklabels(structure_acronyms, minor=True)\n",
    "plt.tick_params(\"y\", which=\"major\", labelleft=False, length=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this matches the structure information saved in the units table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.units.loc[unit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot peak channels for all units recorded in the dentate gyrus (DG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "th_unit_ids = session.units[session.units[\"structure_acronym\"] == \"DG\"].index.values\n",
    "\n",
    "peak_waveforms = []\n",
    "\n",
    "for unit_id in th_unit_ids:\n",
    "\n",
    "    peak_ch = session.units.loc[unit_id, \"peak_channel_id\"]\n",
    "    unit_mean_waveforms = session.mean_waveforms[unit_id]\n",
    "\n",
    "    peak_waveforms.append(unit_mean_waveforms.loc[{\"channel_id\": peak_ch}])\n",
    "    \n",
    "    \n",
    "time_domain = unit_mean_waveforms[\"time\"]\n",
    "\n",
    "peak_waveforms = np.array(peak_waveforms)\n",
    "plt.pcolormesh(peak_waveforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show the pca of the average waveforms to make sure the units make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Check whether we want this here or in exercises***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca to the averaged waveforms\n",
    "\n",
    "# from sklearn import decomposition\n",
    "# pca = decomposition.PCA(n_components=2)\n",
    "# pca.fit(peak_waveforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# plt.plot(time_domain, pca.components_.T)\n",
    "# plt.title('2 PCA components')\n",
    "\n",
    "\n",
    "# print('Explained variance of 2 components')\n",
    "# print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike histograms and stimulus coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Maybe modify to use stim rather than spontaneous to transition into stim coding?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spon = session.stimulus_presentations.loc[\n",
    "    session.stimulus_presentations[\"stimulus_name\"] == \"spontaneous_activity\", \n",
    "    [\"start_time\", \"stop_time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_spon_id = spon.index.values[0]\n",
    "first_spon_duration = spon.loc[first_spon_id, \"stop_time\"] - spon.loc[first_spon_id, \"start_time\"]\n",
    "\n",
    "# 1 - sec\n",
    "time_step = 1 / 100\n",
    "time_domain = np.arange(0.0, first_spon_duration + time_step, time_step)\n",
    "\n",
    "histograms = session.presentationwise_spike_counts(\n",
    "    bin_edges=time_domain,\n",
    "    stimulus_presentation_ids=spon.index,\n",
    "    unit_ids=None\n",
    ")\n",
    "\n",
    "print(histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the firing rate of neurons in different units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_counts = histograms.spike_counts.values\n",
    "time = histograms[\"time_relative_to_stimulus_onset\"]\n",
    "\n",
    "hist_train_1 = histograms[0,:,0]\n",
    "hist_train_2 = histograms[0,:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(time, hist_train_1, '.')\n",
    "plt.plot(time, hist_train_2, '.')\n",
    "plt.xlabel('Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the mean of the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_histograms = histograms.mean(dim=\"stimulus_presentation_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_histograms.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray.plot as xrplot\n",
    "xrplot.imshow(darray=mean_histograms, x=\"time_relative_to_stimulus_onset\",\n",
    "                                      y=\"unit_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute the correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Move this part to exercises?? operate on means or by trial??***\n",
    "\n",
    "***also this is very slow!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_counts = mean_histograms\n",
    "# num_units = spike_counts.shape[1]\n",
    "\n",
    "# correlations = np.zeros((num_units, num_units))\n",
    "\n",
    "# for ii in range(num_units):\n",
    "#     for jj in range(num_units):\n",
    "#         # normalize spike trains before computation\n",
    "#         spike_train_1=spike_counts[:, ii]\n",
    "# #        spike_train_1=(spike_train_1-np.mean(spike_train_1))/np.std(spike_train_1)/len(spike_train_1)\n",
    "#         spike_train_2=spike_counts[:, jj]\n",
    "# #        spike_train_2=(spike_train_2-np.mean(spike_train_2))/np.std(spike_train_2)/len(spike_train_2)\n",
    "#         correlations[ii, jj] = np.correlate(spike_train_1, spike_train_2)\n",
    "# #        np.correlate(spike_counts[:, ii], spike_counts[:, jj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***add structure boundaries to plot here?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# plt.imshow(np.log10(correlations+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus coding\n",
    "\n",
    "***Construct a basic tuning curve***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Field Potential (LFP)\n",
    "\n",
    "The final aspect of a Neuropixels probe recording we will investigate is the local field potential (LFP). An LFP signal is a direct recordings of extracellular voltage from which individual spike contributions have been removed by low-pass filtering. The remaining signal reflects the population activity of a large number of cells in the vicinity of the probe, primarily through the electrical field effects of synaptic currents (along with other trans-membrane currents).\n",
    "\n",
    "LFP can be especially informative for understanding rhythmic activity or oscillations in neural circuits, which can be identified by some simple time-series analysis of the LFP signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the LFP data from one of the probes in our session.\n",
    "\n",
    "We need to provide this function with a probe id, which we can pull out of the `session.probes` table. \n",
    "\n",
    "(Note that the \"id\" column is the index of the dataframe, and thus must be accessed differently than other columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_id = session.probes.index[0]\n",
    "lfp = session.get_lfp(probe_id)\n",
    "print(lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the LFP time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this data, we'll first use the built-in xarray plotting to generate a quick plot. This is too much data to plot all at once, so we select a subset first. Just as in pandas, we use the `loc` property, but since xarray has named dimensions, we can specify our selections by name rather than by order, using a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = lfp.channel[0]\n",
    "subset = lfp.loc[dict(channel=channel, time=slice(5,15))]\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "subset.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to visualize a specific frequency band by filtering. To do this we'll want to convert our data into standard numpy arrays for easier processing using the DataArray object's `values` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lfp.time.values\n",
    "v = lfp.isel(channel=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "freq_window = (4, 15)\n",
    "filt_order = 3\n",
    "fs = 1/(t[1]-t[0])\n",
    "b, a = scipy.signal.butter(filt_order, freq_window, btype='bandpass', fs=fs)\n",
    "v_alpha = scipy.signal.lfilter(b, a, v)\n",
    "\n",
    "\n",
    "window = [5, 15]\n",
    "idx = np.logical_and(t>=window[0], t<window[1])\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(t[idx], v[idx])\n",
    "plt.plot(t[idx], v_alpha[idx],'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral analysis\n",
    "\n",
    "\n",
    "Next we're going to analyze some spectral properties of this signal using the `scipy.signal` library. \"Spectral\" refers to decomposing a signal into a sum of simpler components identified by their frequencies. The set of frequencies of the components forms a *spectrum* that tells us about the complete signal. You can see a full list of spectral analysis functions in scipy here: https://docs.scipy.org/doc/scipy/reference/signal.html#spectral-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power spectral density (PSD)\n",
    "\n",
    "We first import the package, and inspect the `periodogram` function, which estimates the size of the different frequency components of the signal.\n",
    "\n",
    "** Note: maybe we want to compute this directly from an FFT? but only if that concept is already meaningful, so maybe not...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "help(scipy.signal.periodogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of options that we won't go into here for refining the analysis. The one piece of information we do need is `fs`, the sampling frequency. If we used the default value `fs=1.0` our results would not match the true frequencies of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1/(t[1]-t[0])\n",
    "window = [10, 100]\n",
    "idx = np.logical_and(t>=window[0], t<window[1])\n",
    "\n",
    "f, psd = scipy.signal.periodogram(v[idx], fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the power spectrum on a semilog plot, since power can vary over many orders of magnitude across frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.semilogy(f,psd,'k')\n",
    "plt.xlim((0,100))\n",
    "plt.yticks(size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel('Power ($uV^{2}/Hz$)',size=20)\n",
    "plt.xlabel('Frequency (Hz)',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this representation of the power spectrum is extremely noisy. Luckily, many people have come up with solutions to this problem. Scipy includes a function for Welch's method, which averages out noise by computing many estimates of the power spectrum from overlapping windows of the data. You can find some more references for this approach in the Scipy documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, psd = scipy.signal.welch(v[idx], fs, nperseg=1000)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.semilogy(f,psd,'k')\n",
    "plt.xlim((0,100))\n",
    "plt.yticks(size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel('Power ($uV^{2}/Hz$)',size=20)\n",
    "plt.xlabel('Frequency (Hz)',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the time-frequency profile (\"spectrogram\")\n",
    "\n",
    "We might also be interested in how the frequency content of the signal varies over time. In a neural context, power in different frequency bands is often linked to specific types of processing, so we might explore whether changes in the spectrum coincide with specific behaviors or stimuli.\n",
    "\n",
    "The *spectrogram* is essentially an estimate of the power spectrum computed in a sliding time window, producing a 2D representation of the signal power across frequency and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [10, 20]\n",
    "idx = np.where(np.logical_and(t>=window[0],t<window[1]))[0]\n",
    "\n",
    "f, t_spec, spec = scipy.signal.spectrogram(v[idx], fs=fs, window='hanning',\n",
    "                            nperseg=1000, noverlap=1000-1, mode='psd')\n",
    "# Scipy assumes our signal starts at time=0, so we need to provide the offset\n",
    "t_spec = t_spec + t[window[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the matplotlib `pcolormesh` function to visualize this data as an image. We can pass this function grids of x and y coordinates to get the axis labeling right. We also log-transform the power spectrum and restrict to frequencies less than 100 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmax = 80\n",
    "x_mesh, y_mesh = np.meshgrid(t_spec, f[f<fmax])\n",
    "plot_data = np.log10(spec[f<fmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the spectrum together with the raw signal in subplots. Note that we explicitly set the x-axis limits to align the plots. (Alternatively, it's possible to directly couple the limits of different subplots.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolormesh(x_mesh, y_mesh, plot_data, cmap=cm.jet)\n",
    "plt.xlim(window)\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t[idx], v[idx], 'k')\n",
    "plt.xlim(window)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Voltage (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current source density (CSD) analysis\n",
    "\n",
    "Physically, the LFP is made up of the electric fields from specific current sources (or sinks) in brain tissue, namely individual trans-membrane currents. Under certain simplifying assumptions, this transformation of spatial current distribution into field potential can be inverted to infer the distribution of currents underlying a measurement. This is called the current source density, or CSD. Spatial properties of the LFP are generally better studied in this representation.\n",
    "\n",
    "We have pre-calculated estimates of CSD for each probe during a subset of stimulus presentations, which we access below. Note that the CSD array contains data for 186 channels (half the total), in contrast to the LFP which is only provided for approximately one quarter of the contacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csd = session.get_current_source_density(probe_id)\n",
    "csd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Maybe move this elsewhere***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out where each LFP channel is located in the brain using the function `ecephys_session.intervals_structures`, which will identify channels that serve as reference points for the boundaries between identified brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in the list of channels from the CSD\n",
    "channels = session.channels.loc[csd.channel]\n",
    "structure_acronyms, intervals = ecephys_session.intervals_structures(channels)\n",
    "interval_midpoints = [ (aa + bb) / 2 for aa, bb in zip(intervals[:-1], intervals[1:])]\n",
    "print(structure_acronyms)\n",
    "print(interval_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "xmesh, ymesh = np.meshgrid(csd.time, range(len(csd.channel)))\n",
    "plt.pcolormesh(xmesh, ymesh, csd, vmin=-1e5, vmax=1e5)\n",
    "plt.colorbar(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_yticks(intervals)\n",
    "ax.set_yticks(interval_midpoints, minor=True)\n",
    "ax.set_yticklabels(structure_acronyms, minor=True)\n",
    "\n",
    "# make the long divider lines between intervals\n",
    "plt.tick_params(\"y\", which=\"major\", labelleft=False, length=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Equivalent plot using xarray***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "csd.coords['ichannel']=('channel',range(len(csd.channel)))\n",
    "csd.plot(x='time', y='ichannel', robust=True, cmap=cm.jet)\n",
    "\n",
    "ax.set_yticks(intervals)\n",
    "plt.tick_params(\"y\", which=\"major\", labelleft=False, length=40)\n",
    "ax.set_yticks(interval_midpoints, minor=True)\n",
    "ax.set_yticklabels(structure_acronyms, minor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk3]",
   "language": "python",
   "name": "conda-env-allensdk3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
